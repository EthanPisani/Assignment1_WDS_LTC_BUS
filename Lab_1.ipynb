{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lab 01: Pandas, Numpy, and Statsmodels - Beginner's Guide\n",
    "\n",
    "This notebook is designed to help understand Python and data science. It provides a detailed introduction to three essential libraries: Pandas, Numpy, and Statsmodels.\n",
    "\n",
    "- **Pandas**: A library for data manipulation and analysis, offering powerful data structures like DataFrames.\n",
    "- **Numpy**: A fundamental package for numerical computation in Python, supporting multi-dimensional arrays and mathematical functions.\n",
    "- **Statsmodels**: A library for statistical modeling, enabling users to perform tasks like linear regression and hypothesis testing.\n",
    "\n",
    "By the end of this lab, you will be able to:\n",
    "\n",
    "1. Load and explore data using Pandas.\n",
    "2. Perform basic data manipulations such as selecting, filtering, and creating new columns.\n",
    "3. Use Numpy for numerical operations and understand the concept of vectors and dot products.\n",
    "4. Apply Statsmodels to perform basic statistical analyses, including regression modeling.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas: Working with Tabular Data\n",
    "\n",
    "Pandas is a Python library for data manipulation and analysis. It is especially useful for handling structured data (e.g., tables or spreadsheets).\n",
    "\n",
    "### Key Topics\n",
    "1. Loading data\n",
    "2. Exploring data\n",
    "3. Selecting and filtering data\n",
    "4. Creating new columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install packages to use\n",
    "import sys\n",
    "!{sys.executable} -m pip install \"numpy<2.0\"\n",
    "!{sys.executable} -m pip install pandas\n",
    "!{sys.executable} -m pip install statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Import Libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.regression.linear_model import OLS\n",
    "from IPython.display import display\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Loading Data\n",
    "To load tabular data into Python, we use the `read_csv` method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "file_path = 'possum.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first five rows\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Exploring Data\n",
    "Once the data is loaded, we can explore its structure and contents.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get information about the dataset\n",
    "df.info()\n",
    "\n",
    "# Display basic statistics\n",
    "display(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_1_bracket = df['age']\n",
    "column_1_dot = df.age\n",
    "column_1_loc = df.loc[:, 'age']\n",
    "\n",
    "# Display the column values. They should be the same\n",
    "display(column_1_bracket)\n",
    "display(column_1_dot)\n",
    "display(column_1_loc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Step 5: Creating a New Column\n",
    "Pandas allows us to create new columns by performing operations on existing ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert age from years to days\n",
    "df['age_days'] = df['age'] * 365.25\n",
    "\n",
    "# Display the first five rows\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Step 6: Saving Data\n",
    "You can save the modified DataFrame back to a CSV file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save DataFrame to a new CSV file\n",
    "df.to_csv('updated_possum.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy: Numerical Computing\n",
    "\n",
    "Numpy is a library for numerical operations. It is the backbone for many other scientific libraries in Python.\n",
    "\n",
    "### Key Topics\n",
    "1. Arrays\n",
    "2. Array operations\n",
    "3. Linear algebra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Creating Arrays\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 1D array\n",
    "array_1d = np.array([1, 2, 3, 4, 5])\n",
    "\n",
    "# Create a 2D array\n",
    "array_2d = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "\n",
    "# Display arrays\n",
    "print(\"1D Array:\", array_1d)\n",
    "print(\"2D Array:\\n\", array_2d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Array Operations\n",
    "Numpy arrays support element-wise operations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic arithmetic\n",
    "array = np.array([10, 20, 30])\n",
    "\n",
    "print(\"Addition:\", array + 5)\n",
    "print(\"Multiplication:\", array * 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Step 3: Reshaping Arrays\n",
    "Transform arrays to desired shapes using `reshape`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape a 1D array to 2D\n",
    "array = np.array([1, 2, 3, 4])\n",
    "reshaped_array = array.reshape(2, 2)\n",
    "\n",
    "print(\"Original Array:\", array)\n",
    "print(\"Reshaped Array:\\n\", reshaped_array)\n",
    "print()\n",
    "\n",
    "# Transpose a 2D array\n",
    "x = np.array([1, 2, 3, 4])\n",
    "print(x)\n",
    "print(x.T) #Transposing does not change a 1d array\n",
    "print()\n",
    "\n",
    "y = np.array([[5, 6, 7, 8]])\n",
    "print(y)\n",
    "print(y.T) #Transposing changes a 2d array from a row vector to a column vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "A useful function to transform 1-d arrays into 2-d arrays is the function reshape. We can transform or data into (n,1) shaped arrays using x.reshape(-1,1). When you pass -1 to reshape, you're telling numpy to infer the shape in that dimension. So if I had an array, z, of 3 elements and I called z.reshape(-1,1). This will reshape the array to be a (3,1) array. We didn't have to tell numpy the size for the first dimension, numpy inferred it from the size of the array.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x)\n",
    "\n",
    "z = x.reshape(-1,1)\n",
    "\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Dot Product\n",
    "Perform linear algebra operations like dot products.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define vectors\n",
    "x = np.array([1, 2, 3])\n",
    "y = np.array([4, 5, 6])\n",
    "\n",
    "# Calculate dot product\n",
    "dot_product = np.dot(x, y)\n",
    "print(\"Dot Product:\", dot_product)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Squeeze\n",
    "Reshape array using Squeeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Squeeze on a 2D array to convert it to a 1D array\n",
    "\n",
    "array = np.array([[1, 2, 3]])\n",
    "print(\"Original Array:\", array)\n",
    "\n",
    "# Squeeze the array\n",
    "squeezed_array = np.squeeze(array)\n",
    "\n",
    "print(\"Squeezed Array:\", squeezed_array)\n",
    "# this removes the extra dimension\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Statsmodels: Simple Linear Regression\n",
    "\n",
    "Statsmodels is a library for statistical modeling. Here, we perform a simple linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "# Example dataset\n",
    "x = np.array([1, 2, 3, 4, 5, 6, 8, 11, 12, 13])\n",
    "y = np.array([2, 4, 5, 4, 5, 6, 7, 8, 9, 12])\n",
    "\n",
    "# Add a constant term for the intercept\n",
    "X = sm.add_constant(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Fit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit an Ordinary Least Squares (OLS) model\n",
    "model = OLS(y, X).fit()\n",
    "\n",
    "# Print summary\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explanation of the Terms above\n",
    "\n",
    "## General Model Information:\n",
    "\n",
    "Dep. Variable: The dependent (response) variable (y) being predicted or modeled.\n",
    "\n",
    "Model: Specifies the type of regression model used (in this case, OLS).\n",
    "\n",
    "Method: Indicates the method used to fit the model, which is \"Least Squares.\"\n",
    "\n",
    "No. Observations: Number of data points (observations) used in the model (10 in this case).\n",
    "\n",
    "Df Residuals: Degrees of freedom of residuals, calculated as the number of observations minus the number of model parameters estimated (10 - 2 = 8 here).\n",
    "\n",
    "Df Model: Degrees of freedom of the model, representing the number of predictors (1 predictor here).\n",
    "\n",
    "## Goodness-of-Fit Metrics:\n",
    "\n",
    "R-squared: A measure of how well the independent variable(s) explain the variability in the dependent variable. A value of 0.910 indicates that 91% of the variance in y is explained by the model.\n",
    "\n",
    "Adj. R-squared: Adjusted R-squared accounts for the number of predictors and penalizes adding variables that do not improve the model significantly. Here, it is slightly lower (0.898).\n",
    "\n",
    "F-statistic: Tests the overall significance of the model. Higher values indicate a stronger model. Here, 80.46 suggests the model is highly significant.\n",
    "\n",
    "Prob (F-statistic): The p-value for the F-statistic. A small value (1.90e-05) indicates strong evidence that the model is significant.\n",
    "\n",
    "## Model Selection Metrics:\n",
    "\n",
    "Log-Likelihood: The log of the likelihood function, used in comparison of models. Higher values indicate a better fit.\n",
    "\n",
    "AIC (Akaike Information Criterion): A measure of model quality based on the likelihood and complexity. Lower values indicate a better fit.\n",
    "\n",
    "BIC (Bayesian Information Criterion): Similar to AIC but penalizes model complexity more heavily.\n",
    "\n",
    "## Coefficients Table:\n",
    "\n",
    "coef: The estimated coefficients for the predictors. The const term (2.0228) represents the intercept, and x1 (0.6426) is the slope for the independent variable.\n",
    "\n",
    "std err: The standard error of the coefficients, indicating the variability of the coefficient estimates.\n",
    "\n",
    "t: The t-statistic for testing whether the coefficient is significantly different from zero.\n",
    "\n",
    "P>|t|: The p-value associated with the t-statistic. Small values (e.g., < 0.05) indicate statistical significance. Both const (0.006) and x1 (0.000) are significant.\n",
    "\n",
    "[0.025, 0.975]: The 95% confidence interval for the coefficients."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
